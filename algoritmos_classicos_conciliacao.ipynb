{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filipemcbarros/modelos_classificadores_conciliacao/blob/main/algoritmos_classicos_conciliacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keghPgCXT5dr"
      },
      "source": [
        "# **Bibliotecas utilizadas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkaoQj9aT4Tn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,roc_auc_score,roc_curve,accuracy_score,matthews_corrcoef,f1_score\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ET6hULQ9LM6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCEl91OPqM38"
      },
      "source": [
        "# **Carregamento do dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_csv(\"/content/drive/MyDrive/Colab Notebooks/base_processos/dataset_final.csv\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "8rPXk_eCQByz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGcaae41UD_0"
      },
      "source": [
        "# **Treinamento e geração dos modelos com TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUgUwA53VVv9"
      },
      "outputs": [],
      "source": [
        "# Definir a divisão dos conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(features.values, classes, test_size=0.3, random_state=1234)\n",
        "\n",
        "# Validação Cruzada\n",
        "\n",
        "# TF-IDF vectorize\n",
        "#maxfeatures\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
        "tfidf_train_vectors = tfidf_vectorizer.fit_transform(X_train)\n",
        "tfidf_test_vectors = tfidf_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia_XVLNP-VZL"
      },
      "source": [
        "# **Treinamento e geração dos modelos com Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wmXVxqX-W0c"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "#Selecionar o arquivo com o tamanho da dimensão que deseja gerar a representação CBOW ou Skip-Gram\n",
        "word2vec_model = KeyedVectors.load_word2vec_format('/content/drive/Shared drives/cbow_s600.txt')\n",
        "\n",
        "# Definir a divisão dos conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, classes, test_size=0.3, random_state=1234)\n",
        "\n",
        "# Função para calcular o vetor médio de um conjunto de palavras usando Word2Vec\n",
        "def calculate_mean_vector(words, model):\n",
        "    vectors = []\n",
        "    for word in words:\n",
        "        if word in model:\n",
        "            vectors.append(model[word])\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)  # Vetor de zeros se nenhuma palavra for encontrada\n",
        "\n",
        "# Converter as listas de palavras em vetores médios usando o modelo Word2Vec\n",
        "word2vec_train_vectors = [calculate_mean_vector(words, word2vec_model) for words in X_train]\n",
        "word2vec_test_vectors = [calculate_mean_vector(words, word2vec_model) for words in X_test]\n",
        "\n",
        "word2vec_train_vectors = np.array(word2vec_train_vectors)\n",
        "word2vec_test_vectors = np.array(word2vec_test_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kPcruwuIjUq"
      },
      "source": [
        "# **Modelos TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#Seleção de parâmetros via GridSearch SVC\n",
        "model = SVC()\n",
        "parameters = {\n",
        "    'C':[1.0, 10.0, 100.0, 1000.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, parameters, scoring='f1_macro', cv=5, return_train_score=True, verbose=1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "OqE6-TE4fH89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HMLwopSVRUP"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo SVC\n",
        "from sklearn.svm import SVC\n",
        "svc = SVC(kernel='linear')\n",
        "svc.fit(tfidf_train_vectors,y_train)\n",
        "target_svc = svc.predict(tfidf_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHKCZrq3wY_F"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo SVC Polinomial\n",
        "from sklearn.svm import SVC\n",
        "svcPoly = SVC(kernel='poly', degree=5)\n",
        "svcPoly.fit(tfidf_train_vectors,y_train)\n",
        "target_svc_poly = svcPoly.predict(tfidf_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckT3glrhX6tR"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo SVC Gaussian Kernel\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svcGaussian = SVC(kernel='rbf', C=1000.0)\n",
        "svcGaussian.fit(tfidf_train_vectors,y_train)\n",
        "target_svc_gaussian = svcGaussian.predict(tfidf_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seleção de parâmetros via GridSearch Logistic Regression\n",
        "model = LogisticRegression()\n",
        "parameters = {\n",
        "  'C':[1.0, 10.0, 100.0, 1000.0],\n",
        "  'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, parameters, scoring='f1_macro', cv=5, return_train_score=True, verbose=1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "gk6mzmrXflKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkdMQ4WAwuUg"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(C=10.0, solver='lbfgs')\n",
        "lr.fit(tfidf_train_vectors,y_train)\n",
        "target_lr = lr.predict(tfidf_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seleção de parâmetros via GridSearch Árvore de Decisão\n",
        "model = LogisticRegression()\n",
        "parameters = {\n",
        "  'criterion': ['gini', 'entropy', 'log_loss']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, parameters, scoring='f1_macro', cv=5, return_train_score=True, verbose=1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "brmzo_iGgSt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5DKTXzot1sS"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo Árvore de Decisão\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtc = DecisionTreeClassifier(criterion='entropy')\n",
        "dtc.fit(tfidf_train_vectors, y_train)\n",
        "target_dtc = dtc.predict(tfidf_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dnwn3Ujn_j18"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo XGBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "# Convert the data into DMatrix format, which is required by XGBoost\n",
        "dtrain = xgb.DMatrix(tfidf_train_vectors, label=y_train)\n",
        "dtest = xgb.DMatrix(tfidf_test_vectors, label=y_test)\n",
        "\n",
        "# Set the parameters for XGBoost / Testes dos parâmetros feito em algumas combinações para achar os valores abaixo. GridSearch não foi aplicado aqui e sim a construção de vários modelos com parâmetros diferentes\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'max_depth': 7,\n",
        "    'learning_rate': 0.3,\n",
        "    'n_estimators': 100\n",
        "}\n",
        "\n",
        "# Train the Boosted Trees model\n",
        "bst = xgb.train(params, dtrain)\n",
        "\n",
        "# Make predictions on the test set\n",
        "target_xgb = bst.predict(dtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXY8daudNMY0"
      },
      "source": [
        "# **Modelos Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JtGWf6gNMY0"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo SVC\n",
        "from sklearn.svm import SVC\n",
        "svc = SVC(kernel='linear')\n",
        "svc.fit(word2vec_train_vectors,y_train)\n",
        "target_svc = svc.predict(word2vec_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl3JojpsNMY1"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo SVC Polinomial\n",
        "from sklearn.svm import SVC\n",
        "svcPoly = SVC(kernel='poly', degree=5)\n",
        "svcPoly.fit(word2vec_train_vectors,y_train)\n",
        "target_svc_poly = svcPoly.predict(word2vec_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVM1fNG8NMY1"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo SVC Gaussian Kernel\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svcGaussian = SVC(C=1000.0, kernel='rbf')\n",
        "svcGaussian.fit(word2vec_train_vectors,y_train)\n",
        "target_svc_gaussian = svcGaussian.predict(word2vec_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDRqi2LINMY1"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(C=10.0, solver='lbfgs')\n",
        "lr.fit(word2vec_train_vectors,y_train)\n",
        "target_lr = lr.predict(word2vec_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAMuN5fXNMY1"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo Árvore de Decisão\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtc = DecisionTreeClassifier(criterion='entropy') #criterion{“gini”, “entropy”, “log_loss”}, default=”gini” / splitter{“best”, “random”}, default=”best”\n",
        "dtc.fit(word2vec_train_vectors, y_train)\n",
        "target_dtc = dtc.predict(word2vec_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKT-CRXmNMY2"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo XGBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "# Convert the data into DMatrix format, which is required by XGBoost\n",
        "dtrain = xgb.DMatrix(word2vec_train_vectors, label=y_train)\n",
        "dtest = xgb.DMatrix(word2vec_test_vectors, label=y_test)\n",
        "\n",
        "# Set the parameters for XGBoost\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'max_depth': 7,\n",
        "    'learning_rate': 0.3,\n",
        "    'n_estimators': 100\n",
        "}\n",
        "\n",
        "# Train the Boosted Trees model\n",
        "bst = xgb.train(params, dtrain)\n",
        "\n",
        "# Make predictions on the test set\n",
        "target_xgb = bst.predict(dtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kivldJ0Pu8W"
      },
      "source": [
        "# **Modelo SVC:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woTMJenLWHUG"
      },
      "outputs": [],
      "source": [
        "print('############# Relatório de Classificação - Modelo SVC #############')\n",
        "print()\n",
        "\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, target_svc_gaussian, digits=4))\n",
        "# imprimir a acurácia do modelo\n",
        "print(\"Acurácia: {:.4f}\\n\".format(accuracy_score(y_test, target_svc_gaussian)))\n",
        "# imprimir a área sob da curva\n",
        "print(\"AUC: {:.4f}\\n\".format(roc_auc_score(y_test, target_svc_gaussian)))\n",
        "print(\"MCC:  {:.4f}\\n\".format(matthews_corrcoef(y_test, target_svc_gaussian)))\n",
        "print(\"F1-Score:  {:.4f}\\n\".format(f1_score(y_test, target_svc_gaussian)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djAWepReX6DR"
      },
      "outputs": [],
      "source": [
        "print('#### Matriz de Confusão - Modelo SVC ####')\n",
        "print()\n",
        "cf_matrix = confusion_matrix(y_test,target_svc_gaussian)\n",
        "sns.heatmap(cf_matrix, annot=True, fmt='.0f')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55nTbeI6j0r0"
      },
      "source": [
        "# **Modelo SVC Polynomial:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTH9bclWkGKm"
      },
      "outputs": [],
      "source": [
        "print('############# Relatório de Classificação - Modelo SVC Polynomial #############')\n",
        "print()\n",
        "\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, target_svc_poly, digits=4))\n",
        "# imprimir a acurácia do modelo\n",
        "print(\"Acurácia: {:.4f}\\n\".format(accuracy_score(y_test, target_svc_poly)))\n",
        "# imprimir a área sob da curva\n",
        "print(\"AUC: {:.4f}\\n\".format(roc_auc_score(y_test, target_svc_poly)))\n",
        "print(\"MCC:  {:.4f}\\n\".format(matthews_corrcoef(y_test, target_svc_poly)))\n",
        "print(\"F1-Score:  {:.4f}\\n\".format(f1_score(y_test, target_svc_poly)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kMQoHBAkGR4"
      },
      "outputs": [],
      "source": [
        "print('#### Matriz de Confusão - Modelo SVC Polynomial ####')\n",
        "print()\n",
        "cf_matrix = confusion_matrix(y_test,target_svc_poly)\n",
        "sns.heatmap(cf_matrix, annot=True, fmt='.0f')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3gqvi0Uj1OF"
      },
      "source": [
        "# **Modelo SVC Gaussian:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1z5acvGkG_L"
      },
      "outputs": [],
      "source": [
        "print('############# Relatório de Classificação - Modelo SVC Gaussian #############')\n",
        "print()\n",
        "\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, target_svc_gaussian, digits=4))\n",
        "# imprimir a acurácia do modelo\n",
        "print(\"Acurácia: {:.4f}\\n\".format(accuracy_score(y_test, target_svc_gaussian)))\n",
        "# imprimir a área sob da curva\n",
        "print(\"AUC: {:.4f}\\n\".format(roc_auc_score(y_test, target_svc_gaussian)))\n",
        "print(\"MCC:  {:.4f}\\n\".format(matthews_corrcoef(y_test, target_svc_gaussian)))\n",
        "print(\"F1-Score:  {:.4f}\\n\".format(f1_score(y_test, target_svc_gaussian)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2Q-gpUhkHGm"
      },
      "outputs": [],
      "source": [
        "print('#### Matriz de Confusão - Modelo SVC Gaussian ####')\n",
        "print()\n",
        "cf_matrix = confusion_matrix(y_test,target_svc_gaussian)\n",
        "sns.heatmap(cf_matrix, annot=True, fmt='.0f')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDyfXxQaj1vK"
      },
      "source": [
        "# **Modelo Regressão Logística:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9TVa5VskHnO"
      },
      "outputs": [],
      "source": [
        "print('############# Relatório de Classificação - Modelo Regressão Logística #############')\n",
        "print()\n",
        "\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, target_lr, digits=4))\n",
        "# imprimir a acurácia do modelo\n",
        "print(\"Acurácia: {:.4f}\\n\".format(accuracy_score(y_test, target_lr)))\n",
        "# imprimir a área sob da curva\n",
        "print(\"AUC: {:.4f}\\n\".format(roc_auc_score(y_test, target_lr)))\n",
        "print(\"MCC:  {:.4f}\\n\".format(matthews_corrcoef(y_test, target_lr)))\n",
        "print(\"F1-Score:  {:.4f}\\n\".format(f1_score(y_test, target_lr)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w46iUmh_kHsW"
      },
      "outputs": [],
      "source": [
        "print('#### Matriz de Confusão - Modelo Regressão Logística ####')\n",
        "print()\n",
        "cf_matrix = confusion_matrix(y_test,target_lr)\n",
        "sns.heatmap(cf_matrix, annot=True, fmt='.0f')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MrsuGEn-5c8"
      },
      "source": [
        "# **Modelo Árvore de Decisão:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5h_bnD_-8Cj"
      },
      "outputs": [],
      "source": [
        "print('############# Relatório de Classificação - Modelo Árvore de Decisão #############')\n",
        "print()\n",
        "\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(y_test, target_dtc, digits=4))\n",
        "# imprimir a acurácia do modelo\n",
        "print(\"Acurácia: {:.4f}\\n\".format(accuracy_score(y_test, target_dtc)))\n",
        "# imprimir a área sob da curva\n",
        "print(\"AUC: {:.4f}\\n\".format(roc_auc_score(y_test, target_dtc)))\n",
        "print(\"MCC:  {:.4f}\\n\".format(matthews_corrcoef(y_test, target_dtc)))\n",
        "print(\"F1-Score:  {:.4f}\\n\".format(f1_score(y_test, target_dtc)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Seetj2-_G1e"
      },
      "outputs": [],
      "source": [
        "print('#### Matriz de Confusão - Modelo  Árvore de Decisão ####')\n",
        "print()\n",
        "cf_matrix = confusion_matrix(y_test,target_dtc)\n",
        "sns.heatmap(cf_matrix, annot=True, fmt='.0f')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-VWMfdtAQWG"
      },
      "source": [
        "# **Modelo Boosted Tree (XGBoost):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1WHYtGo9_xL"
      },
      "outputs": [],
      "source": [
        "# Definir um limite de decisão (exemplo: 0.5)\n",
        "limite_decisao = 0.5\n",
        "\n",
        "# Converter as previsões em classes binárias\n",
        "previsoes_binarias = [1 if predicao > limite_decisao else 0 for predicao in target_xgb]\n",
        "\n",
        "# Converter os rótulos reais em classes binárias\n",
        "rotulos_binarios = [1 if rotulo > limite_decisao else 0 for rotulo in y_test]\n",
        "\n",
        "print('############# Relatório de Classificação - Modelo XGBoost #############')\n",
        "print()\n",
        "\n",
        "print(\"Relatório de Classificação:\\n\", classification_report(rotulos_binarios, previsoes_binarias, digits=4))\n",
        "\n",
        "print(\"Acurácia: {:.4f}\\n\".format(accuracy_score(rotulos_binarios, previsoes_binarias)))\n",
        "# imprimir a área sob da curva\n",
        "print(\"AUC: {:.4f}\\n\".format(roc_auc_score(rotulos_binarios, previsoes_binarias)))\n",
        "print(\"MCC:  {:.4f}\\n\".format(matthews_corrcoef(rotulos_binarios, previsoes_binarias)))\n",
        "print(\"F1-Score:  {:.4f}\\n\".format(f1_score(rotulos_binarios, previsoes_binarias)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgQKzTye_PEz"
      },
      "outputs": [],
      "source": [
        "print('#### Matriz de Confusão - Modelo XGBoost ####')\n",
        "print()\n",
        "cf_matrix = confusion_matrix(y_test,previsoes_binarias)\n",
        "sns.heatmap(cf_matrix, annot=True, fmt='.0f')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TqyRH0URQ3Af",
        "FKjNiukxrd-1",
        "ECYr3JAUhGUN"
      ],
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}